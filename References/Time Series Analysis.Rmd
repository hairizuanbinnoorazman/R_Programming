---
title: "Time Series Analysis"
output: html_document
---

## Introduction

Time series analysis can be done with native R objects such as vector, matrix and data.frame objects. However, in some cases, the information in those native object may contain all the functionality required to do a full analysis on a time series dataset

```{r}
#install.packages("zoo")
library(zoo)

# Getting the data to play around with zoo package
# install.packages("quantmod")
library(quantmod)
library(dplyr)
chartSeries(AAPL)
timeData <- data.frame(AAPL)
timeData <- mutate(timeData, Date = row.names(timeData))
timeData <- select(timeData, Date, AAPL.Close)

# Passing the data to zoo
aapl <- read.zoo(timeData)
```

## Understanding what is within the aapl zoo dataset

```{r}
plot(aapl, main = "Apple Closing Prices on NASDAQ", ylab = "Prices (USD)", xlab = "Date")

# Get the data point where aapl was the maximum
aapl[which.max(aapl)]

# Get the data point where aapl was the minimum
aapl[which.min(aapl)]

ret_simple <- diff(aapl) / lag(aapl, k = -1) * 100
ret_count <- diff(log(aapl)) * 100

# coredata strips of all "time" attributes within the xts dataset
summary(coredata(ret_simple))

quantile(ret_simple, probs = 0.01)

# Histogram of returns
hist(ret_simple, breaks = 100, main = "Histogram of Simple Returns", xlab = "%")
```

With the above graph, we can somewhat say that there is a roughly an equal chance of gaining/losing when buying this stock (in simple man terms). The returns roughly follow a normal distributions that is centered around the 0 mark.

## Restricting the analysis to a shorter time frame

```{r}
aapl_2013 <- window(aapl, start = "2013-01-01", end = "2013-12-31")
aapl_2013[which.max(aapl_2013)]
```

## Modelling time series data

### ARIMA

Time series models involves decomposing it into trends, seasonal, cyclical and irregular components. One modelling technique available for use would be the ARIMA models. However, when using the ARIMA models, the models are made simpler by ignoring lags of the past y-variables on itself. E.g. Amount of money in your bank account today is dependent on amount of moeny in your bank account last month. It would overestimate the relationship between dependent and independent variables.

As mentioned earlier, ARIMA techniques is used to break up the time series data such after you remove the trends, and its other components, what would be left is simply white noise. White noise is the "error" term of the whole time series data set and is said to be series in which every point in the series is a random draw from a population with zero mean and constant variance

ARIMA consists of 2 parts AR (Auto Regressive) and MA (moving average) models.

AR models are models in which the value of a variable in one period is related to its values in previous periods

```{r}
data <- read.zoo("../Data/UKHP.csv", sep = ",", header = TRUE, format = "%Y-%m", FUN = as.yearmon)

# Function frequency returns the time period - quarterly would be 4 and monthly would be 12
frequency(data)

# Calculate simple returns
hp_ret <- diff(data) / lag(data, k = - 1) * 100
hist(hp_ret, breaks = 100, main = "Histogram of Simple Returns", xlab = "%")
```

We would be using the ARIMA (Autoregressive Integrated Moving Average) time series models. This model is based on the assumption that the current value can only depend on past values of the time series or past values of error terms from the past.

We would use the auto.arima function provided in the forecast package to identify the optimal model and estimate the coefficients

```{r}
mod <- auto.arima(data, stationary = TRUE, seasonal = FALSE, ic = "aic")
# Restricted to stationary models
# Restricted to non-seasonal models
# Quality of model calculated with the Akaike Information Critera

mod
```

Refer to the following site for full details
https://sites.google.com/site/econometricsacademy/econometrics-models/time-series-arima-models
